<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">toja.io</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://toja.io/feed.xml" />
<link rel="alternate" type="text/html" href="http://toja.io" />
<updated>2014-12-01T09:38:01-03:00</updated>
<id>http://toja.io/</id>
<author>
  <name>Osvaldo Toja</name>
  <uri>http://toja.io/</uri>
  <email>osvaldo.toja@gmail.com</email>
</author>


  

<entry>
  <title type="html"><![CDATA[Velocity Barcelona Dia 2]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/velocity-barcelona-dia-2/" />
  <id>http://toja.io/velocity-barcelona-dia-2</id>
  <published>2014-12-01T07:05:17-03:00</published>
  <updated>2014-12-01T07:05:17-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;h1 id=&quot;segundo-da&quot;&gt;Segundo Día&lt;/h1&gt;

&lt;h2 id=&quot;upgrading-the-web-polyfills-components-and-the-future-of-web-development-at-scalehttpvelocityconfcomvelocityeu2014publicscheduledetail37693&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37693&quot;&gt;Upgrading the Web: Polyfills, Components and the Future of Web Development at Scale&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;La charla giró en torno a un producto creado por la empresa del ponente: FT Labs y Fastly que hace la vida mas fácil para los diseñadores y programadores al mismo tiempo que a los encargados de asegurar el performance de la aplicación web.
Empezó hablando de &lt;a href=&quot;http://origami.ft.com/&quot;&gt;Origami&lt;/a&gt; un estándar de componentes para la creación del frontend de sitios web. Una de las ventajas de su implementación fue la reducción de esfuerzos duplicados a la hora de mantener distintas versiones de un mismo sitio.&lt;/p&gt;

&lt;p&gt;Estos componentes utilizan tecnologías que no siempre están presentes en todos los navegadores, como por ejemplo funcionalidades de HTML 5, para suplir esto se utilizan los polyfills. Los polyfills son código que se descargan, implementan esas tecnologías y le permiten a las viejas versiones de los navegadores poder mostrar una página creada con los últimos estandares web.&lt;/p&gt;

&lt;p&gt;Para facilitar servir los polyfills, crearon un &lt;a href=&quot;https://cdn.polyfill.io/&quot;&gt;servicio&lt;/a&gt; que a través  de la CDN de Fastly sirve estos polyfills on demand. De manera automática, en base al &lt;code&gt;User-Agent&lt;/code&gt; prepara selectivamente y envia el paquete de polyfills que necesita ese navegador para completar las funcionalidades que le estarían faltando.&lt;/p&gt;

&lt;p&gt;Más info &lt;a href=&quot;http://labs.ft.com/2014/09/polyfills-as-a-service/&quot;&gt;aquí&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/financial-times/polyfill-service&quot;&gt;Github Repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cdn.oreillystatic.com/en/assets/1/event/121/Upgrading%20the%20Web_%20Polyfills,%20Components%20and%20the%20Future%20of%20Web%20Development%20at%20Scale%20Presentation.pdf&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;monitoring-without-alerts---and-why-it-makes-way-more-sense-than-you-might-thinkhttpvelocityconfcomvelocityeu2014publicscheduledetail39064&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/39064&quot;&gt;Monitoring without Alerts - and Why it Makes Way More Sense than You Might Think&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Traza que no vas a mirar, no la loguees. Las trazas generan alertas. No por tener más alertas vamos a resolver mejor los problemas. Además, para ser realmente efectiva, la alerta necesita un contexto. Presentó el producto de su compañia que permite todo esto. El demo esta disponible en el sitio web http://ruxit.com&lt;/p&gt;

&lt;h2 id=&quot;velocity-at-githubhttpvelocityconfcomvelocityeu2014publicscheduledetail39131&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/39131&quot;&gt;Velocity at GitHub&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Chicos, Github enterprise esta disponible en Amazon AWS.&lt;/p&gt;

&lt;p&gt;Ah, y los logos son muy divertidos.&lt;/p&gt;

&lt;h2 id=&quot;lightning-demoshttpvelocityconfcomvelocityeu2014publicscheduledetail37195&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37195&quot;&gt;Lightning Demos&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Ilya Grigorik de Google mostró como analizar volumenes de datos utilizando BigQuery y Google Cloud Dataflow. Como base de datos utilizo el HTTP Archive, que contiene mas de 300K sitios web y archiva los archivos descargados de los mismos. 
En el sitio http://bigqueri.es se pueden armar sentencias de búsqueda en un lenguaje similar al SQL pero con expresiones regulares y encontrar por ejemplo, una clasificación en base a los tiempos de cache de la páginas que están utilizando los sitios móbiles. Hay ejemplos de búsquedas ya creadas en el sitio a manera de guía de la potencialidad de esta herramienta.&lt;/p&gt;

&lt;p&gt;La parte divertida vino a continuación. A partir de un &lt;a href=&quot;http://geeksta.net/geeklog/exploring-expressions-emotions-github-commit-messages/&quot;&gt;proyecto&lt;/a&gt; que analizaba las emociones de los programadores de cada lenguaje a partir del análisis de los commits en Github, realizó un experimento similar en base a los códigos HTML, CSS y JavaScript. ¿Que relevancia tiene esto en una conferencia sobre rendimiento de sitios web? Que las mismas búsquedas se pueden aplicar a encontrar, por ejemplo, de que maneras estan cargando el codigo JavaScript los sitios. Esto ya es algo con un impacto directo en el rendimiento del sitio. Spoiler: los resultados no fueron muy buenos, casi nadie usa async o defer :(&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.igvita.com/&quot;&gt;Sitio web de Ilya Grigorik&lt;/a&gt; (tiene cosas muy buenas, vale la pena echarle un vistazo)&lt;/p&gt;

&lt;p&gt;El segundo demo fue de &lt;a href=&quot;https://github.com/IteraSpeed/OpenSpeedMonitor&quot;&gt;OpenSpeedMonitor&lt;/a&gt;, una herramienta opensource que automatiza la medición del rendimiento de páginas web, basado en &lt;a href=&quot;http://www.webpagetest.org/&quot;&gt;webpagetest&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Ambas presentaciones estuvieron buenas, el &lt;a href=&quot;http://www.youtube.com/watch?v=_CMcaYnBt-g&quot;&gt;Video&lt;/a&gt; dura 18 mins pero pasan rápido.&lt;/p&gt;

&lt;h2 id=&quot;etsys-journey-to-building-a-continuous-integration-infrastructure-for-mobile-appshttpvelocityconfcomvelocityeu2014publicscheduledetail37081&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37081&quot;&gt;Etsy’s Journey to Building a Continuous Integration Infrastructure for Mobile Apps&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Etsy libera código a producción más de 50 veces al dia en el sitio web, pero para las aplicaciones para móbiles el proceso no es tán sencillo. Apple se demora un promedio de 5 dias en evaluar una app con lo cual, en caso de un error, el rollback no es tán sencillo.&lt;/p&gt;

&lt;p&gt;Armaron un pipeline interno para probar las apps, utilizan &lt;a href=&quot;https://github.com/nomad/shenzhen/&quot;&gt;shenzhen&lt;/a&gt; para firmar las apps, las buildean en un pool de 25 mac minis (deployadas mediante Chef).&lt;/p&gt;

&lt;p&gt;Fue interesante conocer que no utilizan branches para el desarrollo. El código nuevo va en el mismo código base, diferenciandose mediante “feature flags”. Admitió que se corre el riesgo al ir deprecando funcionalidades quede código viejo sin usar, pero prefiere ese riesgo a favor de la facilidades comparando a los problemas de compatibilidad que introduce el código basado en branches (para una empresa que comitea todos los dias, si haces hoy un branch para desarrollar una funcionalidad que te toma un mes, es muy probable que cuando vayas a mergear de vuelta tu código, ya el base se haya diferenciado demasiado del código sobre el que habias hecho el fork en primera instancia).&lt;/p&gt;

&lt;p&gt;Como un detalle técnico, mencionó la herramienta &lt;a href=&quot;https://github.com/etsy/TryLib&quot;&gt;TryLib&lt;/a&gt; que permite testear en los jenkins el código antes de comitearlo al repo.&lt;/p&gt;

&lt;p&gt;Tercerizan el testeo en equipos físicos a https://appthwack.com/.&lt;/p&gt;

&lt;p&gt;Escribir los unit tests no le gusta a nadie. Para buscarle un ángulo divertido, implementaron los “testing dojos”, donde 6 desarrolladores se rotan cada 3 minutos para escribir una funcionalidad, por un lado tener el tiempo limitado, por otro tener tiempo para ver los otros desarrolladores como van escribiendo el código ayuda además a fomentar el trabajo en equipo.&lt;/p&gt;

&lt;p&gt;Para lo que es QA directamente, habló sobre dos técnicas, una es la creacion de equipos compuestos por 8 voluntarios, un facilitador de QA y un grupo de dispositivos que se juntan durante una hora con el objetivo de encontrar la mayora cantidad de bugs durante ese tiempo. La otra es una herramienta &lt;a href=&quot;https://github.com/etsy/BugHunt-iOS&quot;&gt;BugHunt&lt;/a&gt; que le permite a los desarolladores postear capturas de pantallas de los bugs que van encontrando, convirtiendolo en un juego al llevar un ranking.&lt;/p&gt;

&lt;h2 id=&quot;its-3am-do-you-know-why-you-got-pagedhttpvelocityconfcomvelocityeu2014publicscheduledetail37141&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37141&quot;&gt;It’s 3AM, Do You Know Why You Got Paged?&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;El contexto de las alarmas es importante. 
Mostró un gráfico con el número de alertas por año. Hubieron dos descensos significativos. El primero, cuando el equipo de operaciones se tomó una semana entera, sin hacer nada más, para revisar todas las alarmas que tenian en los nagios, y hacer limpieza.&lt;/p&gt;

&lt;p&gt;La segunda, cuando implementaron &lt;a href=&quot;https://github.com/etsy/nagios-herald&quot;&gt;nagios-herald&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;breaking-news-at-1000mshttpvelocityconfcomvelocityeu2014publicscheduledetail37127&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37127&quot;&gt;Breaking News at 1000ms&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;En estos tiempos donde la percepción en la velocidad de carga de un sitio web es tan importante, &lt;a href=&quot;http://www.theguardian.com&quot;&gt;The Guardian&lt;/a&gt; encontró una manera de estar en la delantera entre los sitios de noticios. Incluyen en el código fuente de la página todo lo que es necesario para que carguen los elementos principales de que se compone la página. Por ejemplo, en la página de un árticulo lo importante es mostrar el texto del árticulo, pero no sólo el contenido sino el diseño en su formato final támbien. Incluyen el código css y el javascript en el html inicial que se envia al navegador cuando se accede a la URL. De esta manera, cuando está manera, cuando la pagina carga ya muestra la noticia directamente. A continuación envían el resto del contenido: comentarios, anuncios, etc. Interesante la charla y en las slides mostraba como otros sitios de noticias mostraban una página en blanco en el navegador (mientras este aún estaba esperando por cargar archivos de css o js antes de decidir como iba a mostrar el contenido) ya el sitio de ellos mostraba el contenido, en su formato final.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://speakerdeck.com/patrickhamann/breaking-news-at-1000ms-velocity-eu-2014&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;using-promise-theory-to-improve-digital-service-qualityhttpvelocityconfcomvelocityny2014publicscheduledetail35740&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityny2014/public/schedule/detail/35740&quot;&gt;Using Promise Theory to Improve Digital Service Quality&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Wikipedia dice que la &lt;a href=&quot;http://en.wikipedia.org/wiki/Promise_theory&quot;&gt;Promise Theory&lt;/a&gt;: “es un modelo de cooperación voluntaria entre individuos, agentes o actores autónomos que comunican sus intenciones entre ellos en forma de promesas.&lt;/p&gt;

&lt;p&gt;Una promesa es una declaración de intención con el propósito de incrementar la certidumbre del destinatario con respecto al reclamo de una conducta pasada, presente o futura. Para que una promesa incremente la certidumbre el destinatario necesita creer en el que promete, pero la confianza también puede provenir del conocimiento de promesas anteriores que fueron cumplidas, de esta manera se aprecia que la confianza mantiene una relación simbiótica con las promesas.”&lt;/p&gt;

&lt;p&gt;¿Como se relaciona esto con nuestro mundo? Para empezar asumiendo que las promesas, como tales, no necesariamente se cumplen. Los sistemas en el mundo real son colecciones de agentes autónomos colaborando a través de promesas. De este modo, el reconocimiento de la incertidumbre nos brinda un mayor grado de certidumbre. Además, al tratar a los agentes como autónomos, incrementamos la escalabilidad y la robustez de nuestros sistemas.&lt;/p&gt;

&lt;p&gt;Luego pasó a hablar de los servicios. El servicio es acerca de las experiencias, no las cosas físicas. Las relaciones, no las transacciones. Los proveedores de servicios promete a sus usuarios a ayudarlos a concluir sus objetivos. Todos los elementos que integran una organización de servicios deben colaborar para cumplir con las promesas a sus usuarios.&lt;/p&gt;

&lt;p&gt;Es importante hacernos preguntas como: ¿Qué promesas debemos hacer?, ¿Que promesas necesitamos que otros nos hagan a nosotros?, ¿Que debemos hacer para incrementar la confianza que nos tienen otros?, ¿Que promesas nos deben hacer nuestros usuarios?&lt;/p&gt;

&lt;p&gt;La teoría de la promesa ayuda a cruzar fronteras, a establecer relaciones entre todos los integrantes de la organización. Ayuda entonces modelar la organización a partir del usuario en el flujo que siguen los mismos y definir los servicios con los que interactua.&lt;/p&gt;

&lt;p&gt;Hay que ver las relaciones en términos de promesas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Beneficios&lt;/li&gt;
  &lt;li&gt;Empatía&lt;/li&gt;
  &lt;li&gt;Autonomía&lt;/li&gt;
  &lt;li&gt;Resistencia al fallo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Todo esto en el contexto de todas las áreas de la organización.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.ingineering.it/&quot;&gt;Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/ingineeringit/promising-digital-service-quality&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-bbc-sport-scales-engineeringhttpvelocityconfcomvelocityeu2014publicscheduledetail37176&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37176&quot;&gt;How BBC Sport Scales Engineering&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Tenian el problema de un ciclo de release muy largo, esto incrementaba el nivel de riesgo y de frustración. Armaron un pipeline de continuous deployment similar al que usamos en OLX.
Para deployar el código evaluaron 4 variantes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;El código puesto en un equipo directamente.&lt;/li&gt;
  &lt;li&gt;El código puesto en un container puesto en un equipo.&lt;/li&gt;
  &lt;li&gt;El código puesto en un paquete instalado en un equipo.&lt;/li&gt;
  &lt;li&gt;El código puesto en un paquete instalado en un container puesto en un equipo.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Las dos primeras tenian un problema: ¿cómo expresas dependencias en tu software sin paquetes? (y no me digan con bash scripts)&lt;/p&gt;

&lt;p&gt;Conclusión: Deja el manejo de dependencia de versiones a los sistemas diseñados a tal efecto: los gestores de paquetes.&lt;/p&gt;

&lt;p&gt;Ya sea que usas contenedores o deployas directo a un equipo, empaqueta tu código.&lt;/p&gt;

&lt;p&gt;Respecto a la opción de deployar contenedores (docker) es un tema dinámico:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;las herramientas de deployment y administración aun son inmaduras.&lt;/li&gt;
  &lt;li&gt;es dificil el manejo de dependencias entre el codigo deployado en el container&lt;/li&gt;
  &lt;li&gt;etc &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;La solución elegida entonces fue: código -&amp;gt; paquete -&amp;gt; equipo.&lt;/p&gt;

&lt;p&gt;Crean dos binarios:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Paquetes (e.g. rpm, deb, etc)&lt;/li&gt;
  &lt;li&gt;Imagenes de Equipos (e.g. AMI)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Principios Importantes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Los binarios deben crearse de forma que sea repoducible.&lt;/li&gt;
  &lt;li&gt;Solo se crean los binarios una vez.&lt;/li&gt;
  &lt;li&gt;Deja el manejo de dependencias a las herramientas creadas para la tarea.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hay distintos niveles de manejo de paquetes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Específicos del sistema, e.g. apt, yum&lt;/li&gt;
  &lt;li&gt;Portables, e.g. pip, bundle, npm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Para manejar dependencias entre distintos tipos de manejadores de paquetes se recomienda empaquetar para el nivel mas bajo y luego, resolver las dependencias a nivel mas alto en el momento de buildear incluyendolas en el paquete final.&lt;/p&gt;

&lt;p&gt;Usar CI es crítico, la elección de CI es irrelevante.&lt;/p&gt;

&lt;p&gt;Buildean el código dentro de chroots creados on-demand con &lt;a href=&quot;http://fedoraproject.org/wiki/Projects/Mock&quot;&gt;mock&lt;/a&gt; lo que les asegura que todas las dependencias en tiempo de build esten especificadas correctamente y el build es reproducible.&lt;/p&gt;

&lt;p&gt;¿Como crean los paquetes?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Usan jenkins&lt;/li&gt;
  &lt;li&gt;Crean los paquetes dentro de chroots usando mock.&lt;/li&gt;
  &lt;li&gt;Los servicios son empaquetados como archivos rpm.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;¿Qué hay en una imagen de equipo?&lt;/p&gt;

&lt;p&gt;Crean dos imagenes (AMIs)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Una con el sistema operativo y los paquetes de los servicios&lt;/li&gt;
  &lt;li&gt;Una que toma como base la imagen anterior y le agrega los paquetes con las configuraciones. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;De esta manera pueden re-utilizar la misma imagen con el sistema operativo y los paquetes de los servicios a la hora de crear las imagenes que se deployan en los distintos ambientes.&lt;/p&gt;

&lt;p&gt;Es una solución de compromiso entre las dos opciones: crear una imagen básica que se deploya para luego instalar todos los paquetes sobre la misma ó crear una imagen que tenga todos los paquetes que va a llevar y este lista para ser deployada y funcionar al momento.&lt;/p&gt;

&lt;p&gt;Utilizan AWS Cloudformation y el concepto de Infrastructura como código, esto les permite:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Manejar las dependencias de infrastructura&lt;/li&gt;
  &lt;li&gt;Soportan rollbacks&lt;/li&gt;
  &lt;li&gt;Reproducible&lt;/li&gt;
  &lt;li&gt;Versionan la infrasctura con el código.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Esto permite:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deployar copias idénticas del servicio en distintos ambientes&lt;/li&gt;
  &lt;li&gt;Pueden versionar los templates de infrastructura en código y ser capaces entonces de reproducir todo el stack en cualquier momento en el tiempo.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Entonces, la aplicación no es solo código, son código e infrastructura combinados.&lt;/p&gt;

&lt;p&gt;¿Como provisionan la infrastructura?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Separan en distintos templates la infrastuctura stateless de la stateful.&lt;/li&gt;
  &lt;li&gt;Usa &lt;a href=&quot;https://github.com/cloudtools/troposphere&quot;&gt;librerias de abstracción de Cloudformation&lt;/a&gt; para generar programáticamente los templates.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si no están utilizando Autoscaling Groups, lo están haciendo mal!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ASGs se asegura de que tus instancias siempre esten corriendo.&lt;/li&gt;
  &lt;li&gt;ASGs maneja multi AZ por usted.&lt;/li&gt;
  &lt;li&gt;ASGs hacen de usted un mejor ingeniero.&lt;/li&gt;
  &lt;li&gt;ASGs pueden deployar servicios.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Es importante olvidarse de las instancias como tal, son solo una unidad de capacidad computacional.&lt;/p&gt;

&lt;p&gt;¿Cómo queda todo junto?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Utilice subnets VPCs y ACLs para limitar el acceso por red a sus servicios.&lt;/li&gt;
  &lt;li&gt;Siempre distribuya su infrastructura entre multiple AZs&lt;/li&gt;
  &lt;li&gt;Utilice múltiples cuentas de AWS para distintos servicios y/o ambientes.&lt;/li&gt;
  &lt;li&gt;Corra su servicio en ASGs.&lt;/li&gt;
&lt;/ul&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/velocity-barcelona-dia-2/&quot;&gt;Velocity Barcelona Dia 2&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on December 01, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Velocity Barcelona Dia 1]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/velocity-barcelona-dia-1/" />
  <id>http://toja.io/velocity-barcelona-dia-1</id>
  <published>2014-11-28T07:59:02-03:00</published>
  <updated>2014-11-28T07:59:02-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;h1 id=&quot;primer-dia&quot;&gt;Primer dia&lt;/h1&gt;

&lt;h1 id=&quot;keynotes&quot;&gt;Keynotes&lt;/h1&gt;

&lt;h2 id=&quot;life-after-human-errorhttpvelocityconfcomvelocityeu2014publicscheduledetail37751&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37751&quot;&gt;Life after ‘Human Error’&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;El presentador no era una persona del mundo de sistemas sino un sicólogo. Llamó la atención sobre como existen muchas palabras para definir el error pero solo una para el éxito. Mostró como los medios atribuyen los errores al factor humano como el único causante cuando en realidad es una mezcla de factores. &lt;/p&gt;

&lt;p&gt;También mencionó estudios que demuestran que la presión influye proporcionalmente en el incremento de la tasa de error.&lt;/p&gt;

&lt;p&gt;Se puede leer mas sobre el tema en este &lt;a href=&quot;http://www.infoq.com/news/2014/11/human-error-velocity-conference&quot;&gt;post&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;lightning-demo-always-keep-an-eye-on-your-website-performance---perfbarhttpvelocityconfcomvelocityeu2014publicscheduledetail38145&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/38145&quot;&gt;LIGHTNING DEMO: Always Keep an Eye on Your Website Performance - PerfBar&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Es un script en js que te permite graficar la performance de la pagina. Se podría decir que es un New Relic para pobres ;)
Muy sencillo e interesante, a tener en cuenta para los entornos de desarrollo.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://lafikl.github.io/perfBar/&quot;&gt;Website&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-impatience-economy-where-velocity-creates-valuehttpvelocityconfcomvelocityeu2014publicscheduledetail39554&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/39554&quot;&gt;The Impatience Economy, Where Velocity Creates Value&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;La charla comenzo con el tema del marketing, en particular las aplicaciones Real-Time Bidding (RTB), tipo google adwords, te presentan anuncios en basados en un grupo de criterios, calculando todo eso en tiempo real.&lt;/p&gt;

&lt;p&gt;Se mostró como el producto de su empresa &lt;a href=&quot;http://www.aerospike.com/&quot;&gt;Aerospike&lt;/a&gt; permitió escalar a varios clientes su performance al tiempo que disminuían el número de servidores sin incrementar el los administradores del sistema. Es un producto de base de datos tipo mongodb.&lt;/p&gt;

&lt;p&gt;Mencionaba como en los sitios se tiene una capa de datos sirviendo el frontend y se empieza a tener una capa de datos en el backend donde se guarda toda la data historica relacionada con el trafico del sitio y sus usuarios. Mientras que la capa que sirve el frontend se entiende la importancia de su optimizacion, no tanto la capa del frontend. El producto que vende apunta a ofrecer rendimiento en esa capa de backend.&lt;/p&gt;

&lt;p&gt;La conclusión es que además de prestarle atención a la capa de datos que sirve el frontend, la capa de datos del backend empieza a tomar relevancia y su rendimiento pasa a ser un elemento a tomar en cuenta en la arquitectura de la aplicación.&lt;/p&gt;

&lt;h2 id=&quot;recruiting-for-diversity-in-techhttpvelocityconfcomvelocityeu2014publicscheduledetail36013&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/36013&quot;&gt;Recruiting for Diversity in Tech&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Las comunidades se forman a imagen y semejanza de sus líderes. Si aplicamos el criterio de la meritocracia en solitario, y tenemos un grupo de líderes WASP (y masculinos), la comunidad, eventualmente terminará excluyendo a aquellos que no conforman ese grupo. Es importante tener un grupo de líderes diverso, diverso en cuanto a sexo, nacionalidad, estado social, etc. Ahi entonces si podemos decir que la meritocracia funciona.&lt;/p&gt;

&lt;p&gt;Este principio se aplica a comunidades, empresas, etc.&lt;/p&gt;

&lt;p&gt;Y no pasa solo por la meritocracia, en cualquier sistema de gestión van a aplicarse estos principios.&lt;/p&gt;

&lt;p&gt;Como incorporar la diversidad? empezando por el principio, contrantando con un criterio diverso.&lt;/p&gt;

&lt;h2 id=&quot;better-performance-through-better-designhttpvelocityconfcomvelocityeu2014publicscheduledetail37705&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37705&quot;&gt;Better Performance Through Better Design&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Una de las formas que tenemos de mejorar el rendimiento es mejorando la presentación de los datos relacionados con el rendimiento.&lt;/p&gt;

&lt;p&gt;Una cosa es decirle a un jefe de producto que el sitio demora 2.03 segundos en cargar y que necesitamos mejorar esa performance y otra, es mostrarle un gráfico donde se muestran los tiempos de carga de nuestro sitio comparandolo con los tiempos de los sitios de la competencia. En el primer ejemplo, nosotros le decimos que necesitamos mejorar, en el segundo, es muy probable que sea el jefe de producto el que nos lo diga (en el caso de que no estuvieramos en la punta).&lt;/p&gt;

&lt;p&gt;Vale la pena mirar la pagina del &lt;a href=&quot;http://speedcurve.com/demo/&quot;&gt;demo&lt;/a&gt;, es interesante la forma en que muestran el tiempo de carga, el timeline donde se muestra como un sitio ya cargó mientras los otros aún mantienen la pagina en blanco algun tiempo más.&lt;/p&gt;

&lt;h1 id=&quot;sesiones&quot;&gt;Sesiones&lt;/h1&gt;

&lt;h2 id=&quot;continuous-and-visible-security-testing-with-bdd-securityhttpvelocityconfcomvelocityeu2014publicscheduledetail37137&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37137&quot;&gt;Continuous and Visible Security Testing with BDD-Security&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Interesante charla, mostrando un nuevo uso para las mismas técnicas y herramientas. En este caso, las tradicionales de BDD en el campo de la seguridad.&lt;/p&gt;

&lt;p&gt;Hay que partir de la seguridad como un ciudadano de primera clase en la aplicación. Luego, tenemos el problema de como aplicarla de manera más transparante y sencilla posible. &lt;/p&gt;

&lt;p&gt;Las herramientas presentadas en esta sesión son un paso en este sentido.&lt;/p&gt;

&lt;p&gt;Utilizando lenguaje natural, defines las reglas que quieres implementar y al ejecutar los tests, te aseguras de que las modificaciones en el código no introduzcan problemas de seguridad en la aplicación.&lt;/p&gt;

&lt;p&gt;La ventaja de usar BDD es que las reglas quedan documentadas. &lt;/p&gt;

&lt;p&gt;Se mostró un framework que integra todo el proceso. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cdn.oreillystatic.com/en/assets/1/event/121/Continuous%20and%20Visible%20Security%20Testing%20with%20BDD-Security%20Presentation.pptx&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;monitoring-the-math-behind-bad-behaviorhttpvelocityconfcomvelocityeu2014publicscheduledetail36976&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/36976&quot;&gt;Monitoring: The Math Behind Bad Behavior&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Esta charla giró en torno al tema del manejo de datos, por ejemplo las trazas. Como las técnicas actuales manejan promedios de los datos cuando en realidad no es una buena idea, ya que por ejemplo, un pico puede quedar ignorado cuando se cacula el promedio entre un largo grupo de datos.&lt;/p&gt;

&lt;h2 id=&quot;design-reviews-for-operationshttpvelocityconfcomvelocityeu2014publicscheduledetail37146&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/37146&quot;&gt;Design Reviews for Operations&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Un checklist de cosas que hay que tener en cuenta a la hora de desarrollar un producto que cubren el lado de operaciones y performance. No siempre tenidas en cuenta como parte del parte del proceso, por eso un checklist ahorra palabras y hace más fácil el proceso.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cdn.oreillystatic.com/en/assets/1/event/121/Design%20Reviews%20for%20Operations%20Presentation.zip&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cognitive-biases-in-engineering-organizationshttpvelocityconfcomvelocityeu2014publicscheduledetail36806&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/36806&quot;&gt;Cognitive Biases in Engineering Organizations&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;El cerebro humano esta condicionado en formas en las que uno no se percibe concientemente. La charla giró en torno a tres de esas preconcepciones que directamente afectan nuestro trabajo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fundamental Attribution Error&lt;/strong&gt; Es cuando le atribuimos a otros motivaciones sin una base real que las justifique, solo porque miramos la situacion desde nuestro punto de vista sin deternernos a considerar que pueden haber otras razones fuera de nuestro conocimiento que provocan el comportamiento o accion de la otra persona.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Confirmation Bias&lt;/strong&gt; Es la tendencia que tenemos a prestarle mas atencion inconcientemente, a las cosas que justifican nuestros pensamientos o hipotesis. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hyperbolic Discounting&lt;/strong&gt; Es la tendencia a elegir cosas que nos ofrecen beneficios a corto plazo en vez de las que lo ofrecen a largo plazo, aún cuando el beneficio sea menor.&lt;/p&gt;

&lt;p&gt;Si se sienten identificado con alguna de ellas, evítela :)&lt;/p&gt;

&lt;p&gt;La charla esta publicada en el blog del autor &lt;a href=&quot;http://www.jonathanklein.net/2013/06/cognitive-biases-in-software-engineering.html&quot;&gt;enlace&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-machine-is-dead-long-live-the-machine---service-resilience-and-deployment-automation-at-the-bbchttpvelocityconfcomvelocityeu2014publicscheduledetail36837&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/36837&quot;&gt;The Machine is Dead, Long Live the Machine! - Service Resilience and Deployment Automation at The BBC&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Interesante charla sobre la forma en que la BBC organizo su pipeline de deployment, desde los desarrolladores hasta produccion.&lt;/p&gt;

&lt;p&gt;Miren las slides, vale la pena.&lt;/p&gt;

&lt;p&gt;tl;dr: los desarrolladores comitean, los jenkins testean, se crean paquetes que se instalan en imagenes AMI. Se crean dos imagenes, una con el código de la aplicación y otra con el codigo de la aplicación y la configuración para el entorno de pruebas. Una vez que el código se prueba y esta listo para producción, se promueve. Se crea una imagen a partir de la que tenia el código de la aplicación, esta vez sumandole la configuración para produccion.&lt;/p&gt;

&lt;p&gt;La configuración se maneja toda por separado de la aplicación e incluye tanto configuración de la aplicación en sí como de los servicios del sistema (apache, etc).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cdn.oreillystatic.com/en/assets/1/event/121/The%20Machine%20is%20Dead,%20Long%20Live%20the%20Machine_%20-%20Service%20Resilience%20and%20Deployment%20Automation%20at%20The%20BBC%20Presentation.pdf&quot;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;your-place-or-mine-a-discussion-of-where-to-host-your-sitehttpvelocityconfcomvelocityeu2014publicscheduledetail39647&quot;&gt;&lt;a href=&quot;http://velocityconf.com/velocityeu2014/public/schedule/detail/39647&quot;&gt;Your Place or Mine: A Discussion of Where to Host Your Site&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Fue un panel donde se discutieron las ventajas y desventajas de hospedar un sitio en servidores físicos ó en la nube. &lt;/p&gt;

&lt;p&gt;Conclusión: depende de cada caso.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/velocity-barcelona-dia-1/&quot;&gt;Velocity Barcelona Dia 1&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on November 28, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Organizing Group Vars Files in Ansible]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/using-host-and-group-vars-files-in-ansible/" />
  <id>http://toja.io/using-host-and-group-vars-files-in-ansible</id>
  <published>2014-09-14T22:51:11-03:00</published>
  <updated>2014-09-14T22:51:11-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;from &lt;a href=&quot;http://docs.ansible.com/intro_inventory.html#splitting-out-host-and-group-specific-data&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In addition to the storing variables directly in the INI file, host and group variables can be stored in individual files relative to the inventory file.&lt;/p&gt;

&lt;h2 id=&quot;directory-layout&quot;&gt;directory layout&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;production/
├── group_vars
│   └── server.yml
└── inventory
staging/
├── group_vars
│   └── server
└── inventory
group-vars.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;playbook&quot;&gt;playbook&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# group-vars.yml
- hosts: all
  user: osvaldo
  sudo: no
  gather_facts: False

  tasks:
     - debug: msg=&quot;reading from &quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;files-in-production-directory&quot;&gt;files in production directory&lt;/h2&gt;

&lt;p&gt;inventory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# production/inventory
[server]
localhost   ansible_connection=local
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;vars&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# production/group_vars/server.yml
env_name: production
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;files-in-staging-directory&quot;&gt;files in staging directory&lt;/h2&gt;

&lt;p&gt;inventory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# staging/inventory
[server]
localhost   ansible_connection=local
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;vars&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;# staging/group_vars/server
env_name: staging
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;executing-the-playbook&quot;&gt;executing the playbook&lt;/h2&gt;

&lt;p&gt;using data from staging directory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ ansible-playbook -i staging group-vars.yml

PLAY [all] ********************************************************************

TASK: [debug msg=&quot;reading from &quot;] *********************************
ok: [localhost] =&amp;gt; {
    &quot;msg&quot;: &quot;reading from staging&quot;
}

PLAY RECAP ********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;using data from production directory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ ansible-playbook -i production group-vars.yml

PLAY [all] ********************************************************************

TASK: [debug msg=&quot;reading from &quot;] *********************************
ok: [localhost] =&amp;gt; {
    &quot;msg&quot;: &quot;reading from production&quot;
}

PLAY RECAP ********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Interesting fact: &lt;code&gt;ansible-playbook&lt;/code&gt; when provided a directory as the inventory, will search by default a file named inventory so no need to specify &lt;code&gt;-i production/inventory&lt;/code&gt;, only &lt;code&gt;-i production&lt;/code&gt; will work just fine.&lt;/p&gt;
&lt;/blockquote&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/using-host-and-group-vars-files-in-ansible/&quot;&gt;Organizing Group Vars Files in Ansible&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on September 14, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Install Ansible in CentOS 5.3]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/install-ansible-in-centos-5-3/" />
  <id>http://toja.io/install-ansible-in-centos-5-3</id>
  <published>2014-09-14T22:50:52-03:00</published>
  <updated>2014-09-14T22:50:52-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;install-ansible-in-centos-5-3&lt;/p&gt;

&lt;p&gt;30 Jan 14 @ 14:48&lt;/p&gt;

&lt;p&gt;Using ansible in CentOS 5.3 can be done via a handful of simple steps.&lt;/p&gt;

&lt;h4 id=&quot;installation&quot;&gt;Installation&lt;/h4&gt;

&lt;p&gt;First we install python modules. Ansible is available via package managers but not for CentOS 5.3 so a git based installation will be used.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;/home/rls/bin/python/bin/pip install paramiko PyYAML jinja2 httplib2
cd ~/bin
git clone git://github.com/ansible/ansible.git
sed -i &#39;1 s/python$/python2.7/&#39; ansible/bin/ansible*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After cloning the repository, the binary scripts are modified in order to use our custom python 2.7 installation.&lt;/p&gt;

&lt;h4 id=&quot;test-installation&quot;&gt;Test installation&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;source bin/ansible/hacking/env-setup
echo &quot;127.0.0.1 ansible_python_interpreter=/home/rls/bin/python/bin/python2.7  ansible_connection=local&quot; &amp;gt; ~/ansible_hosts
export ANSIBLE_HOSTS=~/ansible_hosts
ansible -i ~/ansible_hosts all -m ping
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;expected output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;
[osvaldo@srv2 ~]$ ansible -i ~/ansible_hosts all -m ping  -o
127.0.0.1 | success &amp;gt;&amp;gt; {&quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;}

[osvaldo@srv2 ~]$
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;post-installation-steps&quot;&gt;Post installation steps&lt;/h4&gt;

&lt;p&gt;Add to &lt;code&gt;~/.bash_profile&lt;/code&gt; the following line.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;source bin/ansible/hacking/env-setup
&lt;/code&gt;&lt;/pre&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/install-ansible-in-centos-5-3/&quot;&gt;Install Ansible in CentOS 5.3&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on September 14, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[How to Get Last Commit Hash in Git]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/how-to-get-last-commit-hash-in-git/" />
  <id>http://toja.io/how-to-get-last-commit-hash-in-git</id>
  <published>2014-03-12T21:15:58-03:00</published>
  <updated>2014-03-12T21:15:58-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;The bash way&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ git log -n1 | grep commit | awk &#39;{print $2}&#39;
fc77768a4f7c460be765012c9a04e9645e4520d2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The git way&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;# short - using h
$ git log --pretty=format:&#39;%h&#39; -n 1
fc77768
# long - using H
$ git log --pretty=format:&#39;%H&#39; -n 1
fc77768a4f7c460be765012c9a04e9645e4520d2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can specify the number of digits of the hash using &lt;code&gt;--abbrev=n&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;$ git show --pretty=%h --abbrev=18
fc77768a4f7c460be7
&lt;/code&gt;&lt;/pre&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/how-to-get-last-commit-hash-in-git/&quot;&gt;How to Get Last Commit Hash in Git&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on March 12, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Parsing in Coffescript]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/parsing-in-coffescript/" />
  <id>http://toja.io/parsing-in-coffescript</id>
  <published>2014-02-26T15:35:04-03:00</published>
  <updated>2014-02-26T15:35:04-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Parsing with regex is simple in coffescript. Just use the same syntax as &lt;a href=&quot;http://www.w3schools.com/jsref/jsref_obj_regexp.asp&quot;&gt;Javascript&lt;/a&gt; as shown below.&lt;/p&gt;

&lt;p&gt;More info &lt;a href=&quot;http://coffeescriptcookbook.com/chapters/regular_expressions/heregexes&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;tl;dr&lt;/p&gt;

&lt;p&gt;for your copy/paste please, just type the following on a &lt;code&gt;coffee&amp;lt;/console&amp;gt;.&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-coffeescript&quot;&gt;string=&quot;wp-theme-acme-2.1.33.zip&quot;
pattern = /^([a-z\-]*)-([\d\.]*).zip/
string.match(pattern)
[component,version] = string.match(pattern)[1...3]
component
version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-coffeescript&quot;&gt;coffee&amp;gt; string=&quot;wp-theme-acme-2.1.33.zip&quot;
&#39;wp-theme-acme-2.1.33.zip&#39;
coffee&amp;gt; pattern = /^([a-z\-]*)-([\d\.]*).zip/
/^([a-z\-]*)-([\d\.]*).zip/
coffee&amp;gt; string.match(pattern)
[ &#39;wp-theme-acme-2.1.33.zip&#39;,
  &#39;wp-theme-acme&#39;,
  &#39;2.1.33&#39;,
  index: 0,
  input: &#39;wp-theme-acme-2.1.33.zip&#39; ]
coffee&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can store the parsed results directly into variables using something like the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[component,version] = string.match(pattern)[1...3]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-coffeescript&quot;&gt;coffee&amp;gt; [component,version] = string.match(pattern)[1...3]
[ &#39;wp-theme-acme&#39;, &#39;2.1.33&#39; ]
coffee&amp;gt; component
&#39;wp-theme-acme&#39;
coffee&amp;gt; version
&#39;2.1.33&#39;
coffee&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/parsing-in-coffescript/&quot;&gt;Parsing in Coffescript&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on February 26, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Http Requests in Coffeescript]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/http-request-in-coffeescript/" />
  <id>http://toja.io/http-request-in-coffeescript</id>
  <published>2014-02-26T15:11:01-03:00</published>
  <updated>2014-02-26T15:11:01-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Coffescript is quite easy.&lt;/p&gt;

&lt;p&gt;The following code shows how to perform an http get request. The script will obtain the string value if exists, and will show an error if the http return code indicates the value doesn’t exist.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;http_get.coffee &lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-coffescript&quot;&gt;http = require &#39;http&#39;

component=&#39;frontend&#39;
url=&quot;http://dev.acme.com/api/conf/key/&quot;+component+&quot;/DEFAULT_DEPLOY_ENV&quot;
console.log url
req = http.get url, (res) -&amp;gt;
  status = res.statusCode
  value = if status == 200 then 1 else 0
  if status == 200
    # ...
    console.log &quot;yey!&quot;
    res.on &#39;data&#39;, (chunk) -&amp;gt;
      console.log(&#39;body: &#39; + chunk)
  else
    # ...
    console.log &quot;i&#39;m not worthy&quot;

req.on &#39;error&#39;, -&amp;gt;
  msg = &quot;not available&quot;
  console.log msg
console.log &quot;done!&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;osvaldo@laptop:~/ $ coffee http_get.coffee
http://dev.acme.com/api/conf/key/frontend/someenv
done!
i&#39;m not worthy
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;osvaldo@laptop:~/ $ coffee http_get.coffee
http://dev.acme.com/api/conf/key/frontend/prod
done!
yey!
body: prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As a bonus note check how the &lt;code&gt;console.log &quot;done!&quot;&lt;/code&gt; is executed before displaying the output from the request. That’s because of the asynchronous nature from the callback function  handling the request.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/http-request-in-coffeescript/&quot;&gt;Http Requests in Coffeescript&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on February 26, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Using Logstash for Artifactory Notifications]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/using-logstash-for-artifactory-notifications/" />
  <id>http://toja.io/using-logstash-for-artifactory-notifications</id>
  <published>2014-02-16T16:44:58-03:00</published>
  <updated>2014-02-16T16:44:58-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;One of the limitations for the opensource version of &lt;a href=&quot;http://www.jfrog.com/home/v_artifactory_opensource_overview&quot;&gt;Artifactory’s jfrog&lt;/a&gt; is notifications for newly added artifacts. We will provide a workaround to that issue.&lt;/p&gt;

&lt;p&gt;Being an app running inside a tomcat container, a  quick inspection on the log file revealed new artifacts creation was being logged in. Below it’s an example taken from the log file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;2014-02-06 14:13:47,259 [art-exec-3091] [INFO ] (o.a.s.a.ArchiveIndexer:102) - The content of the archive: &#39;acme-alfa-3.4.5.zip&#39; was indexed successfully.
2014-02-06 14:19:45,870 [art-exec-3094] [INFO ] (o.a.s.a.ArchiveIndexer:102) - The content of the archive: &#39;acme-beta-3.4.1.zip&#39; was indexed successfully.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A simple solution would had been using a &lt;code&gt;tail -f .. | some_parsing_script.sh&lt;/code&gt;. But that would had implied taking care of the persistance of the script (screen is not &lt;em&gt;that&lt;/em&gt; good). So the search for a generic solution begins.&lt;/p&gt;

&lt;p&gt;Being familiar with logstash it was just a matter of taking a quick look at the documentation and writing down a simple configuration file.&lt;/p&gt;

&lt;p&gt;The configuration files contains three sections:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;input. where you declare the source of the logs. here we’re using a file, the path for the log file and a plus advantage is the support for log files created by commonly used services like tomcat.&lt;/li&gt;
  &lt;li&gt;filter. where we declare the parsing logic, for now, just standard regex parse.&lt;/li&gt;
  &lt;li&gt;output. whenever the filter matches the declared string on this section, an execution will occured. here we send a notification to IRC (via hubot) and execute an ansible playbook on a remote server via ssh.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-conf&quot;&gt;input {
  file {
    type =&amp;gt; &quot;tomcat&quot;
    path =&amp;gt; &quot;/var/log/artifactory/catalina/catalina.out&quot;

  }


}
filter {
   grok {
     match =&amp;gt; [ &quot;message&quot;, &quot;^%{TIMESTAMP_ISO8601:date},%{NUMBER:number}%{GREEDYDATA:data1}The content of the archive: &#39;%{DATA:artifact}&#39;%{GREEDYDATA:data}&quot; ]
   }
}

output {
  if [data] =~ &quot;successfully.$&quot; {
    exec {
      command =&amp;gt; &quot;curl -s -H &#39;Host: hubot.acme.com&#39; &#39;http://10.1.0.10/message/create?room=%23hubot&amp;amp;text=new%20artifact:%20&#39;%{artifact}&quot;
    }
    exec {
      command =&amp;gt; &quot;ssh srv9 /home/bofh/ansible/deploy-pkg.sh %{artifact} prod&quot;
    }
  }

}
&lt;/code&gt;&lt;/pre&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/using-logstash-for-artifactory-notifications/&quot;&gt;Using Logstash for Artifactory Notifications&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on February 16, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA['Staying Alive' by Ghost]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/staying-alive-by-ghost/" />
  <id>http://toja.io/staying-alive-by-ghost</id>
  <published>2014-02-06T14:15:55-03:00</published>
  <updated>2014-02-06T14:15:55-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;This site was meant to be an static site (generated, of course). However, I found some issues with the generated site (links pointing to folder/index.html instead of just folder/) so the decision to run it behind an nginx server was made.&lt;/p&gt;

&lt;p&gt;Today ghost crashed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;/var/www/ghost/toja.io/node_modules/express-hbs/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:444
    throw new Exception(&quot;You must pass a string or Handlebars AST to Handlebar&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Luckily there’re a couple of options: supervisord, init scripts and forever. Being this a temporary setup (the static site version is the ultimate goal remember?) the third option was choosen.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/nodejitsu/forever&quot;&gt;forever&lt;/a&gt;  can be used to run Ghost as a background task. forever will restart the node process if it crashes.&lt;/p&gt;

&lt;p&gt;Installation is simple:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo npm -g install forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Being temporary doesn’t means it should run without leaving any track. Forever allows you to use a log file. Since the daemon will be running under a non-root account a directory was created, owned by the same user the script will be executed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo mkdir /var/www/ghost/logs/
sudo chown osvaldo:osvaldo /var/www/ghost/logs/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, forever will start ghots in development mode. To start Ghost in production mode type &lt;code&gt;NODE_ENV=production forever start index.js&lt;/code&gt;
The command should be run from the ghost installation directory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;cd /var/www/ghost/toja.io/
forever -l /var/www/ghost/logs/toja-io.log start index.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To check if Ghost is currently running type &lt;code&gt;forever list&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;osvaldo@li68-220:~$ forever list
info:    Forever processes running
data:        uid  command             script   forever pid   logfile                         uptime
data:    [0] mnz9 /usr/local/bin/node index.js 20031   20033 /var/www/ghost/logs/toja-io.log 0:0:1:26.478
osvaldo@li68-220:~$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To stop Ghost type &lt;code&gt;forever stop index.js&lt;/code&gt;&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/staying-alive-by-ghost/&quot;&gt;'Staying Alive' by Ghost&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on February 06, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Installing Pip]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/installing-pip/" />
  <id>http://toja.io/installing-pip</id>
  <published>2014-01-30T14:19:49-03:00</published>
  <updated>2014-01-30T14:19:49-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Installation of pip will be done via &lt;code&gt;easy_install&lt;/code&gt;, a command provided by the setuptools package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;cd /var/tmp
wget http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg --no-check-certificate
sh setuptools-0.6c11-py2.7.egg --prefix=/home/osvaldo/bin/python
/home/osvaldo/bin/python/bin/easy_install-2.7 pip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;requires previous &lt;a href=&quot;/installing-python-2-7-in-centos-5-3/&quot;&gt;python 2.7 installation&lt;/a&gt;&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/installing-pip/&quot;&gt;Installing Pip&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 30, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Installing Git in Centos 5.3]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/installing-git-in-centos-5-3/" />
  <id>http://toja.io/installing-git-in-centos-5-3</id>
  <published>2014-01-30T12:04:46-03:00</published>
  <updated>2014-01-30T12:04:46-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo rpm -Uvh http://dl.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm
sudo yum install git-core
&lt;/code&gt;&lt;/pre&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/installing-git-in-centos-5-3/&quot;&gt;Installing Git in Centos 5.3&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 30, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Installing Python 2.7 in CentOS 5.3]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/installing-python-2-7-in-centos-5-3/" />
  <id>http://toja.io/installing-python-2-7-in-centos-5-3</id>
  <published>2014-01-29T10:37:43-03:00</published>
  <updated>2014-01-29T10:37:43-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Ansible requires python 2.6 or newer.
CentOS 5.3 comes with python 2.4, a version which is used by system tools like yum.
In order to run ansible on older CentOS version, an alternative installation is provided below.
The following commands will install Python 2.7 (check section for requirements below) in the user’s directory. No root access is required.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;USER=osvaldo
VERSION=2.7.5
mkdir ~/src
cd ~/src
wget http://python.org/ftp/python/$VERSION/Python-$VERSION.tar.bz2
tar xjf Python-$VERSION.tar.bz2
rm Python-$VERSION.tar.bz2
cd Python-$VERSION
INSTALL_DIR=/home/$USER/bin/python27
mkdir -p $INSTALL_DIR
./configure --prefix=$INSTALL_DIR
make
make install
ln -s $INSTALL_DIR/bin/python27 /home/${USER}/bin/
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;requirements&quot;&gt;Requirements&lt;/h4&gt;

&lt;p&gt;If after the &lt;code&gt;make&lt;/code&gt; step the following error appears&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;[osvaldo@srv2 Python-2.7.5]$ make
running build
running build_ext
INFO: Can&#39;t locate Tcl/Tk libs and/or headers

Python build finished, but the necessary bits to build these modules were not found:
_bsddb             _curses            _curses_panel
_sqlite3           _tkinter           bsddb185
bz2                dbm                gdbm
sunaudiodev
To find the necessary bits, look in setup.py in detect_modules() for the module&#39;s name.

running build_scripts
[osvaldo@srv2 Python-2.7.5]$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following packages should be installed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;post-installation&quot;&gt;Post installation&lt;/h4&gt;

&lt;p&gt;The new binaries should be added to the bin path. This can be done by modifying the &lt;code&gt;~/.bash_profile&lt;/code&gt; to look like the following. Remember to start a new session for the change to apply.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;PATH=$PATH:$HOME/bin:$HOME/bin/python/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example. The following error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;[osvaldo@srv2 tmp]$ sh setuptools-0.6c11-py2.7.egg --prefix=/home/osvaldo/bin/python
setuptools-0.6c11-py2.7.egg: line 3: exec: python2.7: not found
[osvaldo@srv2 tmp]$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Can be fixed after adding the python 2.7 binary scripts to the bin path.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;[osvaldo@srv2 tmp]$ sh setuptools-0.6c11-py2.7.egg --prefix=/home/osvaldo/bin/python
Processing setuptools-0.6c11-py2.7.egg
Copying setuptools-0.6c11-py2.7.egg to /home/osvaldo/bin/python27/lib/python2.7/site-packages
Adding setuptools 0.6c11 to easy-install.pth file
Installing easy_install script to /home/osvaldo/bin/python/bin
Installing easy_install-2.7 script to /home/osvaldo/bin/python/bin
Installed /home/osvaldo/bin/python27/lib/python2.7/site-packages/setuptools-0.6c11-py2.7.egg
Processing dependencies for setuptools==0.6c11
Finished processing dependencies for setuptools==0.6c11
[osvaldo@srv2 tmp]$
&lt;/code&gt;&lt;/pre&gt;


  &lt;p&gt;&lt;a href=&quot;http://toja.io/installing-python-2-7-in-centos-5-3/&quot;&gt;Installing Python 2.7 in CentOS 5.3&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 29, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Previewing Ghost 0.4]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/previewing-ghost-0-4/" />
  <id>http://toja.io/previewing-ghost-0-4</id>
  <published>2014-01-11T16:56:40-03:00</published>
  <updated>2014-01-11T16:56:40-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;
https://ghost.org/download/

git clone git@github.com:TryGhost/Ghost.git
cd Ghost
git submodule update --init
bundle install
sudo npm install -g grunt-cli
npm install
grunt init
npm start

# Front-end will be accesible at http://localhost:2368, Admin is at http://localhost:2368/ghost/.


# buster

pip install buster
buster --version
buster setup

buster generate --domain=http://127.0.0.1:2368
buster preview
buster deploy

# nice! .... (no hice el setup)
&lt;/code&gt;&lt;/pre&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/previewing-ghost-0-4/&quot;&gt;Previewing Ghost 0.4&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 11, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Code Snippets]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/code-snippets/" />
  <id>http://toja.io/code-snippets</id>
  <published>2014-01-01T21:45:37-03:00</published>
  <updated>2014-01-01T21:45:37-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;no matter how pretty ghost might be, proper display of code snippets is a must.&lt;/p&gt;

&lt;p&gt;shell script&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;#!/bin/bash
hostname
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;php code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-php&quot;&gt;&amp;lt;?php
$msg=&quot;hola&quot;;
phpinfo();
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;hum… no coloring syntax. we’ll came back to that later on.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/code-snippets/&quot;&gt;Code Snippets&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 01, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Oh My Ghost]]></title>
  <link rel="alternate" type="text/html" href="http://toja.io/oh-my-ghost/" />
  <id>http://toja.io/oh-my-ghost</id>
  <published>2014-01-01T21:42:57-03:00</published>
  <updated>2014-01-01T21:42:57-03:00</updated>
  <author>
    <name>Osvaldo Toja</name>
    <uri>http://toja.io</uri>
    <email>osvaldo.toja@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;the long title for this post is: “Searching for a blogging tool that’s fun to use, easy, nice looking and a couple more of things”&lt;/p&gt;

&lt;p&gt;fun to use because boring stuff is … well, not fun to use. life’s too short so what’s the point in doing something you’re just not motivated to do in first place.
easy because i’m lazy, you got me.
nice looking because let’s face it dudes, pretty matters, good things don’t have to be ugly, that’s just a bad excuse for not taking care of (good) design.&lt;/p&gt;

&lt;p&gt;will ghost fit the bill? let’s find out …&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://toja.io/oh-my-ghost/&quot;&gt;Oh My Ghost&lt;/a&gt; was originally published by Osvaldo Toja at &lt;a href=&quot;http://toja.io&quot;&gt;toja.io&lt;/a&gt; on January 01, 2014.&lt;/p&gt;</content>
</entry>

</feed>